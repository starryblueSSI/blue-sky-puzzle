{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbce0d4-c76a-4aac-a6c6-fdabacaac2c2",
   "metadata": {},
   "source": [
    "# Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7acc9-d349-44af-80de-a71fe7e6f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages Required\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import emoji\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.parse import unquote\n",
    "import json\n",
    "import io\n",
    "import zstandard\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.precision\", 3) #Set the default Pandas float precision to 2 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ddf7f-83c7-45d6-9da1-ac415bfc6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once\n",
    "# Download NLTK resources (you only need to do this once)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05df344-00c5-41fb-a4f8-6a1e82beb7e2",
   "metadata": {},
   "source": [
    "# Data Loader (Convert data from zst to dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581ce4d-6075-4ed9-ac7d-535048dafb8c",
   "metadata": {},
   "source": [
    "## For Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f8379-85db-4e77-b8a9-4df7f5160d5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import zstandard\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# Function Definitions\n",
    "# ============================================================\n",
    "\n",
    "def read_and_decode_zst(file_path):\n",
    "    \"\"\"\n",
    "    Reads and decompresses a .zst file, then decodes the JSON data into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file_handle:\n",
    "        reader = zstandard.ZstdDecompressor().stream_reader(file_handle)\n",
    "        data = reader.read().decode()\n",
    "        data = pd.read_json(io.StringIO(data), lines=True)\n",
    "    return data\n",
    "\n",
    "def read_and_process_comment_zst(file_path, min_timestamp=1552288722):\n",
    "    \"\"\"\n",
    "    Reads a .zst file line by line, extracts relevant data, and returns two DataFrames:\n",
    "    one with valid data and one with errors.\n",
    "    \"\"\"\n",
    "    selected_data = []\n",
    "    error_data = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_handle:\n",
    "            reader = zstandard.ZstdDecompressor().stream_reader(file_handle)\n",
    "            text_reader = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "            for line in text_reader:\n",
    "                try:\n",
    "                    data_dict = json.loads(line)\n",
    "                    created_utc = int(data_dict.get('created_utc', 0))\n",
    "                    if created_utc >= min_timestamp:\n",
    "                        selected_data.append({\n",
    "                            'author': data_dict.get('author'),\n",
    "                            'author_created_utc': data_dict.get('author_created_utc'),\n",
    "                            'body': data_dict.get('body'),\n",
    "                            'created_utc': data_dict.get('created_utc'),\n",
    "                            'id': data_dict.get('id'),\n",
    "                            'link_id': data_dict.get('link_id'),\n",
    "                            'parent_id': data_dict.get('parent_id'),\n",
    "                            'votes': data_dict.get('score'),\n",
    "                            'retrieved_utc': data_dict.get('retrieved_on'),\n",
    "                            'subreddit': data_dict.get('subreddit'),\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    error_data.append({'error': str(e), 'data': line})\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return None, None\n",
    "\n",
    "    df_selected_data = pd.DataFrame(selected_data)\n",
    "    df_error_data = pd.DataFrame(error_data)\n",
    "\n",
    "    print(f'The earliest comment in the data is UTC {df_selected_data.created_utc.min()}') \n",
    "    print(f'The selected data has {len(df_selected_data)} rows.')\n",
    "    print(f'The data with errors has {len(df_error_data)} rows.')\n",
    "\n",
    "    return df_selected_data, df_error_data\n",
    "\n",
    "def process_zst_and_save(file_path, output_file):\n",
    "    \"\"\"\n",
    "    Processes a .zst file and saves the valid data to a CSV file.\n",
    "    \"\"\"\n",
    "    selected_data, _ = read_and_process_comment_zst(file_path)\n",
    "    if selected_data is not None:\n",
    "        selected_data.to_csv(output_file, index=False)\n",
    "        print(f'Data saved to {output_file}')\n",
    "    else:\n",
    "        print(f\"Failed to process {file_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# Main Code Execution\n",
    "# ============================================================\n",
    "\n",
    "# Initial Data Processing for 'SingaporeRaw_comments.zst'\n",
    "fp_raw_com = 'SingaporeRaw_comments.zst'\n",
    "df_raw_com = read_and_decode_zst(fp_raw_com)\n",
    "\n",
    "# Display columns and earliest date\n",
    "print(\"Columns in the raw data:\")\n",
    "print(df_raw_com.columns.tolist())\n",
    "\n",
    "earliest_timestamp = df_raw_com.created_utc.min()\n",
    "print(f\"Earliest created_utc timestamp: {earliest_timestamp}\")\n",
    "\n",
    "# Convert timestamp to human-readable format\n",
    "earliest_date = datetime.utcfromtimestamp(earliest_timestamp)\n",
    "print(f\"Earliest date (UTC): {earliest_date.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# Sanity check: length of DataFrame\n",
    "print(f\"Length of the raw DataFrame: {len(df_raw_com)}\")\n",
    "\n",
    "# Filter and save columns of interest\n",
    "df_raw = df_raw_com[['author', 'author_created_utc', 'body', 'created_utc', 'id', \n",
    "                     'link_id', 'parent_id', 'score', 'retrieved_utc', 'subreddit']]\n",
    "df_raw.rename(columns={'score': 'votes'}, inplace=True)\n",
    "df_raw.to_csv('raw_com.csv', index=False)\n",
    "\n",
    "# Process additional files\n",
    "file_paths = {\n",
    "    'SingaporeRaw_comments.zst': 'raw_com.csv',\n",
    "    'singapore_comments.zst': 'sg_com.csv',\n",
    "    'taiwan_comments.zst': 'tw_com.csv',\n",
    "    'HongKong_comments.zst': 'hk_com.csv',\n",
    "}\n",
    "\n",
    "for file_path, output_file in file_paths.items():\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    process_zst_and_save(file_path, output_file)\n",
    "\n",
    "# ============================================================\n",
    "# Acknowledgements\n",
    "# ============================================================\n",
    "# Thanks to Emmanuel Djanga for troubleshooting and suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f55a8a-5e96-410f-ad59-b7e09c97fd32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For Reddit Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3bed2-ebcd-4d10-b4f7-1ab8fd262931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import zstandard\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# Function Definitions\n",
    "# ============================================================\n",
    "\n",
    "def read_and_decode_zst(file_path):\n",
    "    \"\"\"\n",
    "    Reads and decompresses a .zst file, then decodes the JSON data into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file_handle:\n",
    "        reader = zstandard.ZstdDecompressor().stream_reader(file_handle)\n",
    "        data = reader.read().decode()\n",
    "        data = pd.read_json(io.StringIO(data), lines=True)\n",
    "    return data\n",
    "\n",
    "def read_and_process_submission_zst(file_path, min_timestamp=1551843493):\n",
    "    \"\"\"\n",
    "    Reads a .zst file line by line, extracts relevant data, and returns two DataFrames:\n",
    "    one with valid data and one with errors.\n",
    "    \"\"\"\n",
    "    selected_data = []\n",
    "    error_data = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_handle:\n",
    "            reader = zstandard.ZstdDecompressor().stream_reader(file_handle)\n",
    "            text_reader = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "            for line in text_reader:\n",
    "                try:\n",
    "                    data_dict = json.loads(line)\n",
    "                    created_utc = int(data_dict.get('created_utc', 0))\n",
    "                    if created_utc >= min_timestamp:\n",
    "                        # Extract relevant fields\n",
    "                        extracted_data = {\n",
    "                            'author': data_dict.get('author'),\n",
    "                            'author_created_utc': data_dict.get('author_created_utc'),\n",
    "                            'body_title': data_dict.get('title', ''),\n",
    "                            'body_text': data_dict.get('selftext', ''),\n",
    "                            'created_utc': data_dict.get('created_utc'),\n",
    "                            'id': data_dict.get('id'),\n",
    "                            'votes': data_dict.get('score'),\n",
    "                            'retrieved_utc': data_dict.get('retrieved_on'),\n",
    "                            'subreddit': data_dict.get('subreddit'),\n",
    "                        }\n",
    "                        # Concatenate body_title and body_text into 'body'\n",
    "                        extracted_data['body'] = f\"{extracted_data['body_title']} {extracted_data['body_text']}\".strip()\n",
    "                        selected_data.append(extracted_data)\n",
    "                except json.JSONDecodeError as json_err:\n",
    "                    error_data.append({'error': f'JSON decoding error: {json_err}', 'data': line})\n",
    "                except Exception as e:\n",
    "                    error_data.append({'error': str(e), 'data': line})\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return None, None\n",
    "\n",
    "    df_selected_data = pd.DataFrame(selected_data)\n",
    "    df_error_data = pd.DataFrame(error_data)\n",
    "\n",
    "    print(f'Based on the modified method, the earliest comment in the data is UTC {df_selected_data.created_utc.min()}') \n",
    "    print(f'The selected data has {len(df_selected_data)} rows.')\n",
    "    print(f'The data with errors has {len(df_error_data)} rows.')\n",
    "\n",
    "    return df_selected_data, df_error_data\n",
    "\n",
    "# ============================================================\n",
    "# Main Code Execution\n",
    "# ============================================================\n",
    "\n",
    "# Process the raw submissions to find the earliest date and columns of interest\n",
    "fp_raw_sub = 'SingaporeRaw_submissions.zst'\n",
    "df_raw_sub = read_and_decode_zst(fp_raw_sub)\n",
    "\n",
    "# Display column names\n",
    "print(\"Columns in the raw data:\")\n",
    "print(df_raw_sub.columns.tolist())\n",
    "\n",
    "# Keep columns of interest and export to CSV\n",
    "df_raw_sub = df_raw_sub[['author', 'author_created_utc', 'title', 'selftext',\n",
    "                         'created_utc', 'id', 'score', 'retrieved_on', 'subreddit']]\n",
    "df_raw_sub.rename(columns={'score': 'votes'}, inplace=True)\n",
    "df_raw_sub.to_csv('raw_sub.csv', index=False)\n",
    "\n",
    "# Print earliest created date\n",
    "earliest_timestamp = df_raw_sub.created_utc.min()\n",
    "print(f\"Earliest created_utc timestamp: {earliest_timestamp}\")\n",
    "\n",
    "# Convert timestamp to human-readable format\n",
    "earliest_date = datetime.utcfromtimestamp(earliest_timestamp)\n",
    "print(f\"Earliest date (UTC): {earliest_date.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# Process additional submission files\n",
    "datasets = [\n",
    "    ('SingaporeRaw_submissions.zst', 'raw_sub.csv'),\n",
    "    ('singapore_submissions.zst', 'sg_sub.csv'),\n",
    "    ('taiwan_submissions.zst', 'tw_sub.csv'),\n",
    "    ('HongKong_submissions.zst', 'hk_sub.csv'),\n",
    "]\n",
    "\n",
    "for input_file, output_file in datasets:\n",
    "    print(f\"Processing {input_file}...\")\n",
    "    selected_data, _ = read_and_process_submission_zst(input_file)\n",
    "    if selected_data is not None:\n",
    "        selected_data.to_csv(output_file, index=False)\n",
    "        print(f'Data saved to {output_file}')\n",
    "    else:\n",
    "        print(f\"Failed to process {input_file}\")\n",
    "\n",
    "# ============================================================\n",
    "# Acknowledgements\n",
    "# ============================================================\n",
    "# Thanks to Emmanuel Djanga for troubleshooting and suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1efcb-c976-4a2c-98cd-be639be14ff3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import Data and Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ed0fe-5075-4178-9540-e034f1c58bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import emoji\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# Function to extract URLs\n",
    "def extract_url(df):\n",
    "    df['extract_url'] = df['body'].apply(extract_url_from_text)\n",
    "    return df\n",
    "\n",
    "def extract_url_from_text(text):\n",
    "    if pd.notna(text):\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        urls = [link.get('href') for link in soup.find_all('a')]\n",
    "        return urls\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Function to parse URLs\n",
    "def parse_url(df):\n",
    "    df['extract_url'] = df['body'].apply(parse_url_from_text)\n",
    "    return df\n",
    "\n",
    "def parse_url_from_text(text):\n",
    "    urls = extract_url_from_text(text)\n",
    "    decoded_urls = [unquote(url) if isinstance(url, str) else '' for url in urls]\n",
    "    return decoded_urls\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(df):\n",
    "    df['cleaned_body'] = df['body'].apply(clean_text_from_text)\n",
    "    return df\n",
    "\n",
    "def clean_text_from_text(text):\n",
    "    if isinstance(text, str):\n",
    "        cleaned_text = html.unescape(text)\n",
    "        soup = BeautifulSoup(cleaned_text, 'html.parser')\n",
    "        cleaned_text = soup.get_text(separator='')\n",
    "        cleaned_text = emoji.demojize(cleaned_text)\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "        cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Function to calculate account age\n",
    "def account_age(df):\n",
    "    df['account_age'] = df['author_created_utc'].apply(account_age_days)\n",
    "    return df\n",
    "\n",
    "def account_age_days(epoch_timestamp):\n",
    "    current_timestamp = datetime.utcnow().timestamp()\n",
    "    account_age_seconds = current_timestamp - epoch_timestamp\n",
    "    account_age_days = account_age_seconds / (24 * 60 * 60)\n",
    "    return round(account_age_days, 2)\n",
    "\n",
    "# Function to count words\n",
    "def count_words(df):\n",
    "    df['raw_wc'] = df['body'].apply(count_words_from_text)\n",
    "    df['proc_wc'] = df['cleaned_body'].apply(count_words_from_text)\n",
    "    return df\n",
    "\n",
    "def count_words_from_text(text):\n",
    "    if isinstance(text, str):\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        word_count = len(cleaned_text.split())\n",
    "        return word_count\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Function to print deletion comments\n",
    "def print_deleted_comments_stats(df, subreddit):\n",
    "    delete_comments = (df['body'] == '[deleted]').sum()\n",
    "    delete_authors = (df['author'] == '[deleted]').sum()\n",
    "    delete_comments_percent = delete_comments / len(df) * 100\n",
    "    delete_authors_percent = delete_authors / len(df) * 100\n",
    "    \n",
    "    print(subreddit)\n",
    "    print(\"Number of '[deleted]' comments:\", delete_comments)\n",
    "    print(\"Number of '[deleted]' authors:\", delete_authors)\n",
    "    print(f\"Percentage of '[delete]' comments: {delete_comments_percent:.2f}%\")\n",
    "    print(f\"Percentage of '[delete]' authors: {delete_authors_percent:.2f}%\\n\")\n",
    "\n",
    "# Function to print deletion submission\n",
    "def print_deleted_submission_stats(df, subreddit):\n",
    "    delete_submission = (df['body_text'] == '[deleted]').sum()\n",
    "    delete_authors = (df['author'] == '[deleted]').sum()\n",
    "    delete_submission_percent = delete_submission / len(df) * 100\n",
    "    delete_authors_percent = delete_authors / len(df) * 100\n",
    "    \n",
    "    print(subreddit)\n",
    "    print(\"Number of '[deleted]' submission:\", delete_submission)\n",
    "    print(\"Number of '[deleted]' authors:\", delete_authors)\n",
    "    print(f\"Percentage of '[delete]' comments: {delete_submission_percent:.2f}%\")\n",
    "    print(f\"Percentage of '[delete]' authors: {delete_authors_percent:.2f}%\\n\")\n",
    "\n",
    "def filter_and_save_deleted_comments(df, filename):\n",
    "    # Filter rows where 'body' or 'author' is '[deleted]'\n",
    "    deleted_rows = df[(df['body'] == '[deleted]') | (df['author'] == '[deleted]')]\n",
    "    \n",
    "    # Save the deleted rows to a new CSV file\n",
    "    original_filename = filename.split('.')[0]\n",
    "    deleted_filename = f'{original_filename}_deleted.csv'\n",
    "    deleted_rows.to_csv(deleted_filename, index=False)\n",
    "    \n",
    "    # Return the dataframe without the deleted rows\n",
    "    return df[(df['body'] != '[deleted]') & (df['author'] != '[deleted]')]\n",
    "\n",
    "def filter_and_save_deleted_submissions(df, filename):\n",
    "    # Filter rows where 'body_text' or 'author' is '[deleted]'\n",
    "    deleted_rows = df[(df['body_text'] == '[deleted]') | (df['author'] == '[deleted]')]\n",
    "    \n",
    "    # Save the deleted rows to a new CSV file\n",
    "    original_filename = filename.split('.')[0]\n",
    "    deleted_filename = f'{original_filename}_deleted.csv'\n",
    "    deleted_rows.to_csv(deleted_filename, index=False)\n",
    "    \n",
    "    # Return the dataframe without the deleted rows\n",
    "    return df[(df['body_text'] != '[deleted]') & (df['author'] != '[deleted]')]\n",
    "\n",
    "# Function to export processed dataframe to CSV with a suffix added to the original filename\n",
    "def export_to_csv(df, filename):\n",
    "    # Extract the original filename without the extension\n",
    "    original_filename = filename.split('.')[0]\n",
    "    # Construct the new filename with the \"_proc.csv\" suffix\n",
    "    new_filename = f'{original_filename}_proc.csv'\n",
    "    # Export dataframe to CSV\n",
    "    df.to_csv(new_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61e4d7-1aa2-4de8-960c-91b58658a413",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 1 - Reddit Comments with Deleted Author / Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ad0a4-cdbf-45a7-b7db-f6496ee24cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and extracting URLs\n",
    "import html  # For HTML unescaping\n",
    "import emoji  # For handling emojis\n",
    "import re  # For regular expressions\n",
    "from datetime import datetime  # For handling date and time\n",
    "\n",
    "# Load datasets\n",
    "datasets = ['raw_com.csv', 'sg_com.csv', 'tw_com.csv', 'hk_com.csv', 'omc_com.csv', 'tomc_com.csv']\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(dataset)\n",
    "    \n",
    "    # Process each dataframe\n",
    "    df = extract_url(df)\n",
    "    df = parse_url(df)\n",
    "    df = clean_text(df)\n",
    "    df = account_age(df)\n",
    "    df = count_words(df)\n",
    "    \n",
    "    # Print deletion statistics\n",
    "    print_deleted_comments_stats(df, dataset)\n",
    "\n",
    "    # Filter and save deleted rows \n",
    "    df = filter_and_save_deleted_comments(df, dataset)\n",
    "    \n",
    "    # Filter out rows with empty 'cleaned_body'\n",
    "    df = df[df['proc_wc'] > 0]\n",
    "    \n",
    "    # Print total number of rows after filtering\n",
    "    print(f'Total Number of Rows (After Dropping Empty Comments) for {dataset}: {len(df)}')\n",
    "    \n",
    "    # Export processed dataframe to CSV with \"_proc.csv\" suffix added to original filename\n",
    "    export_to_csv(df, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683b921-ca84-403a-9d4f-f2fed1fb9a61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 2 - Reddit Submission with Deleted Author / Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819809b-1b67-4864-af6a-97122f2c1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import emoji\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ****************************************************************************\n",
    "# Note the output for the following cell should be submission and not comments\n",
    "# Was reflected as comments because the function was written for comments, but the underlying logic is similiar\n",
    "# Load datasets\n",
    "datasets = ['raw_sub.csv', 'sg_sub.csv', 'tw_sub.csv', 'hk_sub.csv', 'omc_sub.csv', 'tomc_sub.csv']\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(dataset)\n",
    "    \n",
    "    # Process each dataframe\n",
    "    df = extract_url(df)\n",
    "    df = parse_url(df)\n",
    "    df = clean_text(df)\n",
    "    df = account_age(df)\n",
    "    df = count_words(df)\n",
    "    \n",
    "    # Print deletion statistics\n",
    "    print_deleted_submission_stats(df, dataset)\n",
    "\n",
    "    # Filter and save deleted rows \n",
    "    df = filter_and_save_deleted_submissions(df, dataset)\n",
    "    \n",
    "    # Filter out rows with empty 'cleaned_body'\n",
    "    df = df[df['proc_wc'] > 0]\n",
    "    \n",
    "    # Print total number of rows after filtering\n",
    "    print(f'Total Number of Rows (After Dropping Empty Submissions) for {dataset}: {len(df)}')\n",
    "    \n",
    "    # Export processed dataframe to CSV with \"_proc.csv\" suffix added to original filename\n",
    "    export_to_csv(df, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd3fce-68f1-41f9-aecb-4740f15bcb9d",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea227296-539d-40a6-a973-fdef35fc36fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 1: Incivility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399462a-61c2-4e99-9109-b4ffc6c5808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# ============================================================\n",
    "# Initialization\n",
    "# ============================================================\n",
    "\n",
    "# Initialize Snowball stemmer for English\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# List of word/word stems to check for\n",
    "word_stems = [\n",
    "    \"dumb\", \"farc\", \"hypocrit\", \"insan\", \"insecur\", \"irrespons\", \"sham\", \"trivial\", \"unaccept\", \"uneth\", \"unfair\",\n",
    "    \"bigot\", \"bigotri\", \"discrimin\", \"prejudic\", \"racism\", \"racist\", \"segreg\", \"stereotyp\", \"betray\", \"enemi\", \n",
    "    \"insurg\", \"overthrow\", \"riot\", \"threat\", \"threaten\", \"traitor\", \"treason\", \"tyranni\", \"brainwash\", \"deceiv\", \n",
    "    \"decept\", \"dishonest\", \"disingenu\", \"inaccur\", \"incorrect\", \"misinform\", \"mislead\", \"uninform\", \"dysfunct\", \n",
    "    \"infring\", \"obstruct\", \"obstructionist\", \"suppress\", \"unconstitut\", \"chao\", \"debacl\", \"delud\", \"demean\", \n",
    "    \"disrespect\", \"fiasco\", \"inappropri\", \"nasti\", \"vitriol\", \"yell\"\n",
    "]\n",
    "\n",
    "def calculate_proportion_of_word_stems(text):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of words in the text that match the specified word stems.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    \n",
    "    # Convert text to lowercase and tokenize\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stem the tokens\n",
    "    stemmed_tokens = [snowball_stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Calculate the proportion of stemmed tokens that match the word stems\n",
    "    word_count = len(tokens)\n",
    "    count_matches = sum(1 for token in stemmed_tokens if token in word_stems)\n",
    "    \n",
    "    return (count_matches / word_count * 100) if word_count > 0 else 0\n",
    "\n",
    "def process_datasets(datasets):\n",
    "    \"\"\"\n",
    "    Process each dataset to calculate the proportion of word stems in the 'cleaned_body' column.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        df = pd.read_csv(dataset)\n",
    "        df['incivility_prop'] = df['cleaned_body'].apply(calculate_proportion_of_word_stems)\n",
    "        df.to_csv(dataset, index=False)\n",
    "        print(f\"Processed {dataset}\")\n",
    "\n",
    "# ============================================================\n",
    "# Define File List\n",
    "# ============================================================\n",
    "\n",
    "word_stem_datasets = [\n",
    "    'raw_sub_proc.csv', 'sg_sub_proc.csv', 'tw_sub_proc.csv', 'hk_sub_proc.csv',\n",
    "    'raw_com_proc.csv', 'sg_com_proc.csv', 'tw_com_proc.csv', 'hk_com_proc.csv'\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Main Execution\n",
    "# ============================================================\n",
    "\n",
    "process_datasets(word_stem_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5173bc-02bc-4fcd-ab1a-0de72250079c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 1.5: Assessing the Impact of Accounting/Not Accounting for Chinese Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a447d-b273-4493-9b67-4e7355237b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def contains_chinese(text):\n",
    "    \"\"\"\n",
    "    Check if the given text contains Chinese characters.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):  # Check for NaN values\n",
    "        return False\n",
    "    return bool(re.search(r'[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "def analyze_chinese_characters(file_names, text_column, word_count_column, min_word_count):\n",
    "    \"\"\"\n",
    "    Analyze the percentage of rows containing Chinese characters before and after applying a word count filter.\n",
    "    \"\"\"\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name)\n",
    "        \n",
    "        if text_column in df.columns and word_count_column in df.columns:\n",
    "            df['contains_chinese'] = df[text_column].apply(contains_chinese)\n",
    "            \n",
    "            # Calculate percentage of rows containing Chinese characters before filtering\n",
    "            percentage_before = df['contains_chinese'].mean() * 100\n",
    "            \n",
    "            # Apply the word count filter\n",
    "            filtered_df = df[df[word_count_column] > min_word_count]\n",
    "            \n",
    "            # Calculate percentage of rows containing Chinese characters after filtering\n",
    "            percentage_after = filtered_df['contains_chinese'].mean() * 100 if len(filtered_df) > 0 else 0.0\n",
    "            \n",
    "            print(f'File: {file_name}')\n",
    "            print(f'Percentage of rows containing Chinese characters (before filter): {percentage_before:.2f}%')\n",
    "            print(f'Percentage of rows containing Chinese characters (after filter): {percentage_after:.2f}%')\n",
    "        else:\n",
    "            print(f'Column \"{text_column}\" or \"{word_count_column}\" not found in file: {file_name}')\n",
    "\n",
    "# ============================================================\n",
    "# Define File List and Parameters\n",
    "# ============================================================\n",
    "\n",
    "chinese_char_datasets = [\n",
    "    'raw_com_proc.csv',\n",
    "    'sg_com_proc.csv',\n",
    "    'tw_com_proc.csv',\n",
    "    'hk_com_proc.csv'\n",
    "]\n",
    "\n",
    "# Column names for processing\n",
    "text_column_name = 'cleaned_body'\n",
    "word_count_column_name = 'proc_wc'\n",
    "min_word_count = 9  # Minimum word count to apply the filter\n",
    "\n",
    "# ============================================================\n",
    "# Main Execution\n",
    "# ============================================================\n",
    "\n",
    "analyze_chinese_characters(chinese_char_datasets, text_column_name, word_count_column_name, min_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f673b-1acc-4291-95fc-71f976b5f292",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 2: Queer vs. Non-Queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75659bb-9c9d-4f60-89a9-15f2609cd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# Datasets\n",
    "datasets = {\n",
    "    'raw_com': 'raw_com_proc.csv',\n",
    "    'sg_com': 'sg_com_proc.csv',\n",
    "    'tw_com': 'tw_com_proc.csv',\n",
    "    'hk_com': 'hk_com_proc.csv',\n",
    "    'omc_com': 'omc_com_proc.csv',\n",
    "    'tomc_com': 'tomc_com_proc.csv',\n",
    "    'raw_sub': 'raw_sub_proc.csv',\n",
    "    'sg_sub': 'sg_sub_proc.csv',\n",
    "    'tw_sub': 'tw_sub_proc.csv',\n",
    "    'hk_sub': 'hk_sub_proc.csv',\n",
    "    'omc_sub': 'omc_sub_proc.csv',\n",
    "    'tomc_sub': 'tomc_sub_proc.csv'\n",
    "}\n",
    "\n",
    "# Predefined keywords\n",
    "predefined_keywords = [\n",
    "    'gay', 'lesbian', 'lgbt', 'queer', 'homosexual', 'faggot', 'sissy', 'tranny', 'ahkua', 'ahgua'\n",
    "]\n",
    "\n",
    "# Mixed characters list for matching\n",
    "mixed_characters_list = [\n",
    "    '同性戀', '同性恋', '同志', '娘娘腔', '娘炮', '基佬', 'ah kua', 'ah gua'\n",
    "]\n",
    "\n",
    "# Case-insensitive regex pattern\n",
    "pattern = re.compile('|'.join(mixed_characters_list), re.IGNORECASE)\n",
    "\n",
    "## Helper Functions \n",
    "\n",
    "#Function to Find Keyword Matches\n",
    "\n",
    "def find_matches(text, keywords, threshold=90):\n",
    "    \"\"\"Find fuzzy matches of keywords within the text.\"\"\"\n",
    "    text = text.lower()\n",
    "    matches = process.extract(text, keywords, scorer=fuzz.partial_ratio)\n",
    "    matched_keywords = [match[0] for match in matches if match[1] >= threshold]\n",
    "    return matched_keywords\n",
    "\n",
    "#Function to Process a DataFrame\n",
    "\n",
    "def process_dataframe(df):\n",
    "    \"\"\"Process a DataFrame to detect keywords and compute related metrics.\"\"\"\n",
    "    # Ensure 'cleaned_body' column is of type string\n",
    "    df['cleaned_body'] = df['cleaned_body'].astype(str)\n",
    "\n",
    "    # Apply matching functions\n",
    "    df['matched_keywords'] = df['cleaned_body'].apply(lambda x: find_matches(x, predefined_keywords))\n",
    "    df['matched_keywords_mix'] = df['cleaned_body'].str.lower().str.findall(pattern)\n",
    "\n",
    "    # Create binary columns for keyword presence\n",
    "    df['keywords_present_eng'] = df['matched_keywords'].apply(lambda x: 1 if x else 0)\n",
    "    df['keywords_present_mix'] = df['matched_keywords_mix'].apply(lambda x: 1 if x else 0)\n",
    "    df['keywords_present_all'] = df.apply(\n",
    "        lambda row: 1 if (row['keywords_present_eng'] == 1 or row['keywords_present_mix'] == 1) else 0, axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate and print the proportion of rows with LGBTQ-related content\n",
    "    proportion = len(df[df['keywords_present_all'] == 1]) / len(df) * 100\n",
    "    print(f\"Proportion with LGBTQ-related content: {proportion:.3f}%\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489f3f5-c844-46ef-b05e-42429558b1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processing the Datasets\n",
    "\n",
    "def process_and_save_datasets(datasets):\n",
    "    \"\"\"Process each dataset and save the results to a new CSV.\"\"\"\n",
    "    for name, filename in datasets.items():\n",
    "        df = pd.read_csv(filename)\n",
    "        df = process_dataframe(df)\n",
    "        df.to_csv(f'{name}_proc.csv', index=False)\n",
    "\n",
    "process_and_save_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d718dd-6d15-4638-be2d-7c5b94ef012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis - Compute Binary Statistics\n",
    "\n",
    "def compute_binary_stats(file_path, dataset_name):\n",
    "    \"\"\"Compute and print statistics for the 'keywords_present_all' binary column.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'keywords_present_all' in df.columns:\n",
    "        count_ones = df['keywords_present_all'].sum()\n",
    "        count_zeros = len(df) - count_ones\n",
    "        mean_value = df['keywords_present_all'].mean()\n",
    "        std_dev_value = df['keywords_present_all'].std()\n",
    "        \n",
    "        print(f\"Dataset: {dataset_name}\")\n",
    "        print(f\"Count of '1's: {count_ones}\")\n",
    "        print(f\"Count of '0's: {count_zeros}\")\n",
    "        print(f\"Mean of 'keywords_present_all': {mean_value:.3f}\")\n",
    "        print(f\"Standard Deviation of 'keywords_present_all': {std_dev_value:.3f}\\n\")\n",
    "    else:\n",
    "        print(f\"Dataset: {dataset_name} does not contain 'keywords_present_all' column.\\n\")\n",
    "\n",
    "# Iterate through the datasets and compute metrics for each dataset\n",
    "for key, file in datasets.items():\n",
    "    compute_binary_stats(file, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce7eb9-ac2b-4764-81fa-5fbf7037ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics Before and After Filtering for Word Count\n",
    "\n",
    "def compare_before_after_filter(csv_files, min_word_count=9):\n",
    "    \"\"\"Compare the difference in keyword presence before and after filtering.\"\"\"\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Before filtering\n",
    "        percentage_eng_before = df['keywords_present_eng'].mean() * 100\n",
    "        percentage_all_before = df['keywords_present_all'].mean() * 100\n",
    "        difference_before = percentage_all_before - percentage_eng_before\n",
    "        \n",
    "        # Apply filter\n",
    "        filtered_df = df[df['proc_wc'] > min_word_count]\n",
    "        \n",
    "        if not filtered_df.empty:\n",
    "            # After filtering\n",
    "            percentage_eng_after = filtered_df['keywords_present_eng'].mean() * 100\n",
    "            percentage_all_after = filtered_df['keywords_present_all'].mean() * 100\n",
    "            difference_after = percentage_all_after - percentage_eng_after\n",
    "        else:\n",
    "            # No data after filtering\n",
    "            percentage_eng_after, percentage_all_after, difference_after = 0, 0, 0\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"File: {file}\")\n",
    "        print(f\"Difference before filtering: {difference_before:.2f}%\")\n",
    "        print(f\"Difference after filtering: {difference_after:.2f}%\\n\")\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = ['raw_com_proc.csv', 'sg_com_proc.csv', 'tw_com_proc.csv', 'hk_com_proc.csv']\n",
    "\n",
    "compare_before_after_filter(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8f23e-7973-43f1-ad10-b02cbda28789",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 3: Number of Replies (Queer vs. Non-Queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847d8fe-63a3-47f9-9257-95680213d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_merge_dataframes(sub_proc_file, com_proc_file, common_columns):\n",
    "    \"\"\"Load and merge the two CSV files based on the common columns.\"\"\"\n",
    "    df_sub_proc = pd.read_csv(sub_proc_file)\n",
    "    df_com_proc = pd.read_csv(com_proc_file)\n",
    "    \n",
    "    df_com_proc = df_com_proc[common_columns + ['parent_id']]\n",
    "    df_sub_proc = df_sub_proc[common_columns]\n",
    "    \n",
    "    return pd.concat([df_sub_proc, df_com_proc], ignore_index=True)\n",
    "\n",
    "def filter_dataframe_by_keyword(df):\n",
    "    \"\"\"Filter the dataframe by 'keywords_present_all' and return two filtered dataframes.\"\"\"\n",
    "    df_filter_0 = df[df['keywords_present_all'] == 0]\n",
    "    df_filter_1 = df[df['keywords_present_all'] == 1]\n",
    "    \n",
    "    return df_filter_0, df_filter_1\n",
    "\n",
    "def count_occurrences(parent_ids, ids_list):\n",
    "    \"\"\"Count the occurrences of each ID in the parent_id list.\"\"\"\n",
    "    counts = {id_: 0 for id_ in ids_list}\n",
    "    for parent_id in parent_ids:\n",
    "        parent_id = parent_id.split('_')[1]  # Remove the prefix\n",
    "        if parent_id in counts:\n",
    "            counts[parent_id] += 1\n",
    "    return counts\n",
    "\n",
    "def compute_statistics(counts_dict):\n",
    "    \"\"\"Compute count, average, and standard deviation from the occurrence counts.\"\"\"\n",
    "    values = list(counts_dict.values())\n",
    "    count = len(values)\n",
    "    average = np.mean(values)\n",
    "    std_dev = np.std(values)\n",
    "    return count, average, std_dev\n",
    "\n",
    "def process_dataset(sub_proc_file, com_proc_file, common_columns):\n",
    "    \"\"\"Process the dataset, compute statistics, and return the counts and statistics.\"\"\"\n",
    "    df = load_and_merge_dataframes(sub_proc_file, com_proc_file, common_columns)\n",
    "    df_filter_0, df_filter_1 = filter_dataframe_by_keyword(df)\n",
    "\n",
    "    id_list_filter_0 = df_filter_0['id'].tolist()\n",
    "    id_list_filter_1 = df_filter_1['id'].tolist()\n",
    "\n",
    "    parent_ids = df['parent_id'].dropna().tolist()\n",
    "\n",
    "    count_filter_0 = count_occurrences(parent_ids, id_list_filter_0)\n",
    "    count_filter_1 = count_occurrences(parent_ids, id_list_filter_1)\n",
    "\n",
    "    stats_filter_0 = compute_statistics(count_filter_0)\n",
    "    stats_filter_1 = compute_statistics(count_filter_1)\n",
    "\n",
    "    return count_filter_0, stats_filter_0, count_filter_1, stats_filter_1\n",
    "\n",
    "def save_and_print_results(counts, stats, file_prefix):\n",
    "    \"\"\"Save counts to CSV and print statistics.\"\"\"\n",
    "    df_counts = pd.DataFrame(list(counts.items()), columns=('id', 'count'))\n",
    "    df_counts.to_csv(f'{file_prefix}.csv', index=False)\n",
    "    \n",
    "    print(f\"Counts for {file_prefix}:\")\n",
    "    print(df_counts)\n",
    "    print(f\"Statistics: Count = {stats[0]}, Average = {stats[1]:.2f}, Std Dev = {stats[2]:.2f}\")\n",
    "\n",
    "def process_all_datasets(dataset_pairs, common_columns):\n",
    "    \"\"\"Process all dataset pairs and save the results.\"\"\"\n",
    "    for name, (sub_proc_file, com_proc_file) in dataset_pairs.items():\n",
    "        count_filter_0, stats_filter_0, count_filter_1, stats_filter_1 = process_dataset(sub_proc_file, com_proc_file, common_columns)\n",
    "        \n",
    "        save_and_print_results(count_filter_0, stats_filter_0, f'{name}_reply_count_nonqueer')\n",
    "        save_and_print_results(count_filter_1, stats_filter_1, f'{name}_reply_count_queer')\n",
    "\n",
    "# Define common columns and dataset pairs\n",
    "common_columns = [\n",
    "    'author', 'author_created_utc', 'body', 'created_utc', 'id', 'votes', \n",
    "    'retrieved_utc', 'subreddit', 'extract_url', 'cleaned_body', \n",
    "    'account_age', 'raw_wc', 'proc_wc', 'incivility_prop', 'matched_keywords', \n",
    "    'keywords_present_eng', 'matched_keywords_mix', 'keywords_present_mix', \n",
    "    'keywords_present_all'\n",
    "]\n",
    "\n",
    "dataset_pairs = {\n",
    "    'raw': ('raw_sub_proc.csv', 'raw_com_proc.csv'),\n",
    "    'sg': ('sg_sub_proc.csv', 'sg_com_proc.csv'),\n",
    "    'tw': ('tw_sub_proc.csv', 'tw_com_proc.csv'),\n",
    "    'hk': ('hk_sub_proc.csv', 'hk_com_proc.csv'),\n",
    "}\n",
    "\n",
    "# Process all datasets\n",
    "process_all_datasets(dataset_pairs, common_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cf85f-ad6a-4d77-8de7-55d3762ccf70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 4: Number of Votes (Queer vs. Non-Queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df9436-16b7-4f36-801b-f34ae28843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_filenames():\n",
    "    \"\"\"Return the list of filenames to process.\"\"\"\n",
    "    return [\n",
    "        'tomc_com_proc.csv', 'tomc_sub_proc.csv',\n",
    "        'tw_com_proc.csv', 'tw_sub_proc.csv',\n",
    "        'raw_com_proc.csv', 'raw_sub_proc.csv',\n",
    "        'omc_com_proc.csv', 'omc_sub_proc.csv',\n",
    "        'hk_com_proc.csv', 'hk_sub_proc.csv',\n",
    "        'sg_com_proc.csv', 'sg_sub_proc.csv'\n",
    "    ]\n",
    "\n",
    "def get_common_columns():\n",
    "    \"\"\"Return the list of common columns to select from the files.\"\"\"\n",
    "    return ['id', 'votes', 'subreddit', 'keywords_present_all']\n",
    "\n",
    "def read_and_concatenate_files(filenames, common_columns):\n",
    "    \"\"\"Read multiple CSV files and concatenate them into a single DataFrame.\"\"\"\n",
    "    dataframes = [pd.read_csv(file, usecols=common_columns) for file in filenames]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "def calculate_statistics(df):\n",
    "    \"\"\"Calculate descriptive statistics grouped by subreddit and keyword presence.\"\"\"\n",
    "    grouped_stats = df.groupby(['subreddit', 'keywords_present_all'])['votes'].agg(['mean', 'std', 'median'])\n",
    "    print(grouped_stats)\n",
    "    return grouped_stats\n",
    "\n",
    "def export_dataframe(df, output_file):\n",
    "    \"\"\"Export the DataFrame to a CSV file without the index.\"\"\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the data processing and export.\"\"\"\n",
    "    filenames = get_filenames()\n",
    "    common_columns = get_common_columns()\n",
    "    \n",
    "    merged_df = read_and_concatenate_files(filenames, common_columns)\n",
    "    calculate_statistics(merged_df)\n",
    "    export_dataframe(merged_df, 'df_merged_votes.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cb4be-4899-4ebb-b33f-318334ff01ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 5: LIWC - Authentic, Tone, Dic, WC, Prosocial, Polite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecbc0d-c859-474a-bff3-036ae9aa150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation for Feature Extraction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_data_for_extraction(input_files, output_files):\n",
    "    \"\"\"\n",
    "    Prepare data for feature extraction by selecting specific columns and saving to new files.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_files: List of input CSV filenames.\n",
    "    - output_files: List of output CSV filenames corresponding to each input file.\n",
    "    \"\"\"\n",
    "    for input_file, output_file in zip(input_files, output_files):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Select only the 'id' and 'cleaned_body' columns\n",
    "        df_filtered = df[['id', 'cleaned_body']]\n",
    "        \n",
    "        # Export to new CSV file\n",
    "        df_filtered.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"Data preparation complete!\")\n",
    "\n",
    "# List of input and output filenames\n",
    "input_files = [\n",
    "    'raw_com_proc.csv',\n",
    "    'sg_com_proc.csv',\n",
    "    'tw_com_proc.csv',\n",
    "    'hk_com_proc.csv'\n",
    "]\n",
    "\n",
    "output_files = [\n",
    "    'raw_com_liwc_a2.csv',\n",
    "    'sg_com_liwc_a2.csv',\n",
    "    'tw_com_liwc_a2.csv',\n",
    "    'hk_com_liwc_a2.csv'\n",
    "]\n",
    "\n",
    "# Prepare data for feature extraction\n",
    "prepare_data_for_extraction(input_files, output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71b458-6f7e-4cf9-b137-5b036e324f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files will be sent to LIWC-2022 for feature extraction.\n",
    "# Only after this process is complete will the next block of code run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336ab46-ad4c-46fa-bb28-7c84f68ca367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_extraction_issues(filenames):\n",
    "    \"\"\"\n",
    "    Analyze the issues in feature extraction related to 'Authentic' and 'Tone' columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - filenames: List of CSV filenames to analyze.\n",
    "    \"\"\"\n",
    "    total_deleted_due_to_authentic = 0\n",
    "    total_deleted_due_to_both = 0\n",
    "\n",
    "    for filename in filenames:\n",
    "        # Load the data into a DataFrame\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        print(f\"\\nProcessing file: {filename}\")\n",
    "        \n",
    "        # Print total number of comments\n",
    "        print(f\"Total Number of Comments: {len(df)}\")\n",
    "\n",
    "        # Count missing values in the 'Authentic' column\n",
    "        authentic_missing = df['Authentic'].isna().sum()\n",
    "        print(f\"Comments Failed to Extract for Authenticity: {authentic_missing}\")\n",
    "        total_deleted_due_to_authentic += authentic_missing\n",
    "\n",
    "        # Count missing values in the 'Tone' column\n",
    "        tone_missing = df['Tone'].isna().sum()\n",
    "        print(f\"Comments Failed to Extract for Tone: {tone_missing}\")\n",
    "\n",
    "        # Find rows where both 'Authentic' and 'Tone' are NaN\n",
    "        both_missing = df[df['Authentic'].isna() | df['Tone'].isna()]\n",
    "\n",
    "        # Print the number of comments where both are missing\n",
    "        both_missing_count = len(both_missing)\n",
    "        print(f\"Comments Failed to Extract for Both Authenticity & Tone: {both_missing_count}\")\n",
    "\n",
    "        # Update total deleted due to both 'Authentic' and 'Tone'\n",
    "        total_deleted_due_to_both += both_missing_count\n",
    "\n",
    "        # Drop rows where both 'Tone' and 'Authentic' are NaN\n",
    "        df_cleaned = df.dropna(subset=['Authentic', 'Tone'])\n",
    "        print(f\"Number of Comments with both Authenticity and Tone: {len(df_cleaned)}\")\n",
    "\n",
    "        # Number of comments deleted when dropping rows with NaN in both 'Tone' and 'Authentic'\n",
    "        comments_deleted = len(df) - len(df_cleaned)\n",
    "        print(f\"Number of Comments Deleted when dropping rows with NaN in both Authenticity and Tone: {comments_deleted}\")\n",
    "\n",
    "        # Number of comments left if dropping rows with NaN in 'Authentic' only\n",
    "        df_auth = df.dropna(subset=['Authentic'])\n",
    "        print(f\"Number of Comments left if only Authenticity is Dropped: {len(df_auth)}\")\n",
    "\n",
    "    # Print the total number of comments deleted due to excluding 'Authentic' across all files\n",
    "    print(f\"\\nTotal Number of Comments Deleted Due to Excluding Authenticity Across All Files: {total_deleted_due_to_authentic}\")\n",
    "\n",
    "    # Print the total number of comments deleted due to excluding both 'Authentic' and 'Tone' across all files\n",
    "    print(f\"Total Number of Comments Deleted Due to Excluding Both Authenticity and Tone Across All Files: {total_deleted_due_to_both}\")\n",
    "\n",
    "def merge_liwc_output(proc_file, liwc_file, output_file):\n",
    "    \"\"\"\n",
    "    Merge the main DataFrame with the LIWC output.\n",
    "    \n",
    "    Parameters:\n",
    "    - proc_file: Path to the 'proc' CSV file.\n",
    "    - liwc_file: Path to the 'liwc' CSV file.\n",
    "    - output_file: Path where the merged DataFrame will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load DataFrames\n",
    "        df_proc = pd.read_csv(proc_file)\n",
    "        df_liwc = pd.read_csv(liwc_file)\n",
    "        \n",
    "        # Columns to drop from df_proc\n",
    "        columns_to_drop = ['Authentic', 'Tone', 'prosocial', 'polite', 'Segment', 'WC']\n",
    "        \n",
    "        # Drop columns if they exist in df_proc\n",
    "        existing_columns_to_drop = [col for col in columns_to_drop if col in df_proc.columns]\n",
    "        if existing_columns_to_drop:\n",
    "            df_proc = df_proc.drop(columns=existing_columns_to_drop)\n",
    "        else:\n",
    "            print(f\"Warning: None of the columns {columns_to_drop} found in {proc_file}.\")\n",
    "        \n",
    "        # Specify columns to bring over from df_liwc\n",
    "        columns_to_bring = ['id', 'WC', 'Authentic']\n",
    "        \n",
    "        # Perform the merge\n",
    "        df_merged = pd.merge(df_proc, df_liwc[columns_to_bring], on='id', how='left')\n",
    "        \n",
    "        # Save the merged DataFrame to CSV\n",
    "        df_merged.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully processed and saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files {proc_file} and {liwc_file}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Analyze extraction issues for files\n",
    "    extraction_files = [\n",
    "        'raw_com_liwc_a2.csv',\n",
    "        'sg_com_liwc_a2.csv',\n",
    "        'tw_com_liwc_a2.csv',\n",
    "        'hk_com_liwc_a2.csv'\n",
    "    ]\n",
    "    analyze_extraction_issues(extraction_files)\n",
    "\n",
    "    # Define file pairs and output files for merging\n",
    "    file_pairs = [\n",
    "        ('raw_com_proc.csv', 'raw_com_liwc_a2.csv', 'merged_raw_com_proc.csv'),\n",
    "        ('sg_com_proc.csv', 'sg_com_liwc_a2.csv', 'merged_sg_com_proc.csv'),\n",
    "        ('tw_com_proc.csv', 'tw_com_liwc_a2.csv', 'merged_tw_com_proc.csv'),\n",
    "        ('hk_com_proc.csv', 'hk_com_liwc_a2.csv', 'merged_hk_com_proc.csv')\n",
    "    ]\n",
    "    \n",
    "    # Process each file pair for merging\n",
    "    for proc_file, liwc_file, output_file in file_pairs:\n",
    "        merge_liwc_output(proc_file, liwc_file, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ddaa7b-654f-4f17-9ce2-decbbc86edac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 6: Create Additional Reddit Features: 'is_reply' (1 = reply, 0 = top-level comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34237836-6bff-4237-a8d7-9acdc66fdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_columns_comments(df):\n",
    "    \"\"\"\n",
    "    Add 'is_reply' columns to the comments DataFrame based on 'parent_id'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Comments DataFrame to process.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Comments DataFrame with added columns.\n",
    "    \"\"\"\n",
    "    df['is_reply'] = np.where(df['parent_id'].str.startswith('t3'), 0,\n",
    "                           np.where(df['parent_id'].str.startswith('t1'), 1, np.nan))\n",
    "    return df\n",
    "\n",
    "def process_and_export(file_paths):\n",
    "    \"\"\"\n",
    "    Process each comments CSV file, add columns, and export the processed DataFrame as CSV.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths (list of str): List of file paths for comments to process.\n",
    "    \"\"\"\n",
    "    for file_path in file_paths:\n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Apply function to add columns\n",
    "        df = add_columns_comments(df)\n",
    "        \n",
    "        # Ensure DataFrame has the necessary columns\n",
    "        common_columns = ['author','id', 'parent_id','cleaned_body', 'votes', 'account_age', \n",
    "                          'WC', 'incivility_prop','keywords_present_eng', 'matched_keywords_mix',\n",
    "                          'keywords_present_all','Authentic','is_reply','subreddit']\n",
    "        \n",
    "        df = df[common_columns]\n",
    "        \n",
    "        # Export DataFrame to CSV with the same name (overwriting)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Processed and exported: {file_path}\")\n",
    "\n",
    "# File paths to process\n",
    "file_paths_comments = [\n",
    "    'merged_hk_com_proc.csv',\n",
    "    'merged_tw_com_proc.csv',\n",
    "    'merged_sg_com_proc.csv',\n",
    "    'merged_raw_com_proc.csv'\n",
    "]\n",
    "\n",
    "process_and_export(file_paths_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fb6f6-a790-4c18-9a62-da39a73ba756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 7 : Get number of replies, average emotion in replies, average incivility in replies, keeping enteries with more than 9 wordcount in this processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520ce38-8a2c-46a4-ba93-c3161efeda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define functions\n",
    "\n",
    "def count_replies(df):\n",
    "    \"\"\"\n",
    "    Counts the number of replies for each 'id' and adds this information to the dataframe.\n",
    "    \"\"\"\n",
    "    df['parent_id_clean'] = df['parent_id'].str.replace(r'^t[13]_', '', regex=True)\n",
    "    id_counts = df['parent_id_clean'].value_counts().to_dict()\n",
    "    df['num_of_replies'] = df['id'].map(id_counts).fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def merge_incivility(df):\n",
    "    \"\"\"\n",
    "    Calculates the average incivility for each 'parent_id', merges this information\n",
    "    back into the original dataframe, and fills missing values.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy(deep=True)\n",
    "    result = df_copy.groupby('parent_id').agg({'incivility_prop': 'mean'}).reset_index()\n",
    "    result['parent_id'] = result['parent_id'].str.replace(r'^t[13]_', '', regex=True)\n",
    "    result = result.rename(columns={'parent_id': 'id', 'incivility_prop': 'reply_avg_incivility'})\n",
    "    df_merged = pd.merge(df, result, on='id', how='left')\n",
    "    df_merged['reply_avg_incivility'] = df_merged['reply_avg_incivility'].fillna(0)\n",
    "    return df_merged\n",
    "\n",
    "def process_csv_files(input_files, output_files, apply_function, filter_condition=None):\n",
    "    \"\"\"\n",
    "    Processes CSV files: reads, applies a function, optionally filters, and saves the results.\n",
    "    \"\"\"\n",
    "    for input_file, output_file in zip(input_files, output_files):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Apply the specified function\n",
    "        df = apply_function(df)\n",
    "        \n",
    "        # Apply filter condition if specified\n",
    "        if filter_condition:\n",
    "            df = df.query(filter_condition)\n",
    "        \n",
    "        # Save the modified DataFrame back to a new CSV file\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "    print(f\"Processing complete. Modified files saved with the suffix '{output_file.split('_')[-1]}'.\")\n",
    "\n",
    "# Step 1: Get number of replies\n",
    "input_files_step1 = [\n",
    "    'merged_hk_com_proc.csv',\n",
    "    'merged_tw_com_proc.csv',\n",
    "    'merged_sg_com_proc.csv',\n",
    "    'merged_raw_com_proc.csv'\n",
    "]\n",
    "\n",
    "output_files_step1 = [\n",
    "    'merged_hk_com_proc_with_replies.csv',\n",
    "    'merged_tw_com_proc_with_replies.csv',\n",
    "    'merged_sg_com_proc_with_replies.csv',\n",
    "    'merged_raw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "process_csv_files(input_files_step1, output_files_step1, count_replies)\n",
    "\n",
    "# Step 2: Average the replies of incivility, regardless of word count\n",
    "input_files_step2 = [\n",
    "    'merged_hk_com_proc_with_replies.csv',\n",
    "    'merged_tw_com_proc_with_replies.csv',\n",
    "    'merged_sg_com_proc_with_replies.csv',\n",
    "    'merged_raw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "output_files_step2 = [\n",
    "    'hk_com_proc_with_replies.csv',\n",
    "    'tw_com_proc_with_replies.csv',\n",
    "    'sg_com_proc_with_replies.csv',\n",
    "    'raw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "process_csv_files(input_files_step2, output_files_step2, merge_incivility, filter_condition='WC > 9')\n",
    "\n",
    "# Additional Processing: Create final dataset with dummy variables\n",
    "file_paths_final = [\n",
    "    'hk_com_proc_with_replies.csv',\n",
    "    'tw_com_proc_with_replies.csv',\n",
    "    'sg_com_proc_with_replies.csv',\n",
    "    'raw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "# Columns to keep\n",
    "columns_of_interest = ['subreddit', 'keywords_present_all', 'Authentic', 'WC', 'is_reply', 'reply_avg_incivility', 'votes', 'num_of_replies']\n",
    "\n",
    "# Read and concatenate DataFrames\n",
    "dfs = [pd.read_csv(file)[columns_of_interest] for file in file_paths_final]\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Create dummy variables\n",
    "dummies = pd.get_dummies(concatenated_df['subreddit'], prefix='subreddit', drop_first=False)\n",
    "dummies.drop('subreddit_SingaporeRaw', axis=1, inplace=True)\n",
    "\n",
    "# Concatenate dummy variables with the original DataFrame\n",
    "df_final = pd.concat([concatenated_df, dummies], axis=1)\n",
    "df_final[dummies.columns] = df_final[dummies.columns].astype(int)\n",
    "\n",
    "# Export the final DataFrame\n",
    "final_output_file = 'final_dataset.csv'\n",
    "df_final.to_csv(final_output_file, index=False)\n",
    "\n",
    "print(\"Final dataset with dummy variables saved as 'final_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b384827-4dad-409c-bd20-5239a1a8cfc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Descriptive Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481d12-c3b9-4476-95d0-2a35cf1b05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# List of CSV file paths\n",
    "csv_files = [\n",
    "    'hk_com_proc_with_replies.csv',\n",
    "    'tw_com_proc_with_replies.csv',\n",
    "    'sg_com_proc_with_replies.csv',\n",
    "    'raw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "def read_and_concatenate_files(file_paths):\n",
    "    \"\"\"\n",
    "    Reads and concatenates multiple CSV files into a single DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.concat((pd.read_csv(file) for file in file_paths), ignore_index=True)\n",
    "\n",
    "def calculate_stats(dataframe, columns):\n",
    "    \"\"\"\n",
    "    Calculates statistical measures for specified columns in a DataFrame.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        stats[column] = {\n",
    "            'mean': round(dataframe[column].mean(), 2),\n",
    "            'std_dev': round(dataframe[column].std(), 2),\n",
    "            'min': round(dataframe[column].min(), 2),\n",
    "            'max': round(dataframe[column].max(), 2),\n",
    "            'skewness': round(skew(dataframe[column].dropna()), 2),\n",
    "            'kurtosis': round(kurtosis(dataframe[column].dropna()), 2)\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "def print_statistics(stats, title):\n",
    "    \"\"\"\n",
    "    Prints statistical measures for each column in a dictionary.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title}:\")\n",
    "    for column, column_stats in stats.items():\n",
    "        print(f\"\\n{column}:\")\n",
    "        for stat, value in column_stats.items():\n",
    "            print(f\"{stat}: {value}\")\n",
    "\n",
    "# Main script\n",
    "df = read_and_concatenate_files(csv_files)\n",
    "\n",
    "# Print overall DataFrame statistics\n",
    "print(len(df))\n",
    "print(\"\\nSubreddit distribution:\")\n",
    "print(df['subreddit'].value_counts())\n",
    "\n",
    "# Define columns for which statistics are needed\n",
    "columns = ['Authentic', 'WC', 'reply_avg_tone', 'reply_avg_incivility', 'num_of_replies', 'votes']\n",
    "\n",
    "# Get and print overall statistics\n",
    "overall_stats = calculate_stats(df, columns)\n",
    "print_statistics(overall_stats, \"Overall Statistics\")\n",
    "\n",
    "# Filter DataFrame and print statistics for each condition\n",
    "for keyword_value in [1, 0]:\n",
    "    df_filtered = df[df['keywords_present_all'] == keyword_value]\n",
    "    stats = calculate_stats(df_filtered, columns)\n",
    "    print_statistics(stats, f\"Statistics for keywords_present_all == '{keyword_value}'\")\n",
    "    print(f\"Number of records: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa38f8b-f4ff-41c2-9a2c-084832fb7432",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Appendix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88754fd4-a9a2-4215-9ffa-93770df5a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Define the plot_data_loss function\n",
    "def plot_data_loss(df, column, thresholds, file_prefix):\n",
    "    \"\"\"\n",
    "    Plot percentage of data lost for different thresholds on a column in a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - column: Name of the column in df to evaluate\n",
    "    - thresholds: List of values to set as the threshold for column 'WC'\n",
    "    - file_prefix: Prefix from the file name to include in the plot title\n",
    "\n",
    "    Returns:\n",
    "    - None (plots the graph directly)\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    threshold_values = []\n",
    "    percentage_lost = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        df_temp = df.copy()\n",
    "        df_temp.loc[df_temp[column] < threshold, column] = None\n",
    "        \n",
    "        rows_lost = df_temp[column].isnull().sum()\n",
    "        percentage = (rows_lost / total_rows) * 100\n",
    "        \n",
    "        threshold_values.append(threshold)\n",
    "        percentage_lost.append(percentage)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(threshold_values, percentage_lost, marker='o')\n",
    "    plt.title(f'Percentage of Data Lost Due to Minimum Word Count Threshold: {file_prefix}')\n",
    "    plt.xlabel('Minimum Word Count Threshold')\n",
    "    plt.ylabel('Percentage of Data Lost')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Set the x-axis major ticks to be every 2 units\n",
    "    plt.gca().xaxis.set_major_locator(MultipleLocator(2))  # Major ticks on x-axis every 2 units\n",
    "    \n",
    "    # Set the y-axis major ticks to be every 10 units (or use default if preferred)\n",
    "    plt.gca().yaxis.set_major_locator(MultipleLocator(10))  # Major ticks on y-axis every 10 units\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\n",
    "    'hk_com_proc.csv',\n",
    "    'tw_com_proc.csv',\n",
    "    'sg_com_proc.csv',\n",
    "    'raw_com_proc.csv'\n",
    "]\n",
    "\n",
    "# List of thresholds to test\n",
    "thresholds = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "\n",
    "\n",
    "# Iterate through each file path\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "\n",
    "    # Extract the file prefix for use in the plot title\n",
    "    file_prefix = file_path.split('_')[0]\n",
    "    \n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Assuming 'WC' is the column of interest\n",
    "    plot_data_loss(df, 'WC', thresholds, file_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7787b7-0519-47dd-82df-3347e79a3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate the exact percentage of data lost and the number of lost entries for a given threshold on a column in a Pandas DataFrame\n",
    "def calculate_data_loss_at_threshold(df, column, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the exact number of data lost and the percentage of data lost for a given threshold on a column in a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - column: Name of the column in df to evaluate\n",
    "    - threshold: Threshold value to set for column 'WC'\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing the absolute number of entries lost and the percentage of data lost at the given threshold\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    df_temp = df.copy()\n",
    "    df_temp.loc[df_temp[column] < threshold, column] = None\n",
    "    \n",
    "    rows_lost = df_temp[column].isnull().sum()\n",
    "    percentage_lost = (rows_lost / total_rows) * 100\n",
    "    \n",
    "    return rows_lost, percentage_lost\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\n",
    "    'hk_com_proc.csv',\n",
    "    'tw_com_proc.csv',\n",
    "    'sg_com_proc.csv',\n",
    "    'raw_com_proc.csv'\n",
    "]\n",
    "\n",
    "# Define the specific threshold value\n",
    "specific_threshold = 10\n",
    "\n",
    "# Iterate through each file path\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate and get the absolute number of entries lost and the percentage of data lost at the threshold of 10\n",
    "    rows_lost, percentage_lost_at_threshold = calculate_data_loss_at_threshold(df, 'WC', specific_threshold)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Absolute number of entries lost at threshold {specific_threshold} for {file_path}: {rows_lost}\")\n",
    "    print(f\"Percentage of data lost at threshold {specific_threshold} for {file_path}: {percentage_lost_at_threshold:.2f}%\")\n",
    "    print()  # Print a blank line for better readability between files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec251883-8150-4a59-a918-5e0c59858b38",
   "metadata": {},
   "source": [
    "# Logistics Regression (Inference) \n",
    "Purpose: Replicate the Results in R and Obtain Linearity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0e517-aca9-4877-9548-3207040b4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define file path\n",
    "file_path = 'final_dataset.csv'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load dataset and drop rows with missing values in relevant columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna(subset=[\n",
    "        'subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "        'Authentic', 'WC', 'is_reply', 'keywords_present_all'\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def fit_logistic_regression(X, y):\n",
    "    \"\"\"\n",
    "    Fit a logistic regression model and return the fitted model.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    return model\n",
    "\n",
    "def print_model_summary(model):\n",
    "    \"\"\"\n",
    "    Print the summary of a fitted logistic regression model.\n",
    "    \"\"\"\n",
    "    print(model.summary())\n",
    "\n",
    "def print_model_metrics(model):\n",
    "    \"\"\"\n",
    "    Print coefficients, AIC, and BIC of a fitted logistic regression model.\n",
    "    \"\"\"\n",
    "    coefficients = model.params\n",
    "    print(\"Coefficients:\")\n",
    "    for variable, coef in coefficients.items():\n",
    "        print(f\"{variable}: {coef:.2f}\")\n",
    "\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    print(f\"AIC: {round(aic, 2)}\")\n",
    "    print(f\"BIC: {round(bic, 2)}\")\n",
    "\n",
    "def plot_log_odds(X, coefficients, predictors):\n",
    "    \"\"\"\n",
    "    Plot log odds against each predictor.\n",
    "    \"\"\"\n",
    "    log_odds = X.dot(coefficients)\n",
    "    \n",
    "    plt.figure(figsize=(18, 10))\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    \n",
    "    for i, predictor in enumerate(predictors):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        if predictor in X.columns:\n",
    "            plt.scatter(X[predictor], log_odds, color=colors[i], alpha=0.5)\n",
    "            plt.xlabel(predictor)\n",
    "            plt.ylabel('Log Odds')\n",
    "            plt.title(f'Log Odds vs. {predictor}')\n",
    "            plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def nlog(score, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Apply log transformation to handle zero values.\n",
    "    \"\"\"\n",
    "    return np.sign(score) * np.log(np.abs(score) + epsilon)\n",
    "\n",
    "# Model M1: Reddit Source - No Log Transformation\n",
    "df = load_and_preprocess_data(file_path)\n",
    "X1 = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan']]\n",
    "y1 = df['keywords_present_all']\n",
    "model_1 = fit_logistic_regression(X1, y1)\n",
    "print(\"Model 1:\")\n",
    "print_model_summary(model_1)\n",
    "print_model_metrics(model_1)\n",
    "\n",
    "# Model M2: Reddit Source + User-Generated Features (Before Logging)\n",
    "X2 = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "        'Authentic', 'WC', 'is_reply']]\n",
    "y2 = df['keywords_present_all']\n",
    "model_2 = fit_logistic_regression(X2, y2)\n",
    "print(\"\\nModel 2:\")\n",
    "print_model_summary(model_2)\n",
    "print_model_metrics(model_2)\n",
    "plot_log_odds(X2, model_2.params, ['Authentic', 'WC'])\n",
    "\n",
    "# Model M2Log: Reddit Source + User-Generated Features (Logged)\n",
    "df[['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes']] = df[['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes']].apply(nlog)\n",
    "X2_log = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "             'Authentic', 'WC', 'is_reply', 'reply_avg_incivility', 'num_of_replies', 'votes']]\n",
    "y2_log = df['keywords_present_all']\n",
    "model_2Log = fit_logistic_regression(X2_log, y2_log)\n",
    "print(\"\\nModel 2 Log:\")\n",
    "print_model_summary(model_2Log)\n",
    "print_model_metrics(model_2Log)\n",
    "plot_log_odds(X2_log, model_2Log.params, ['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes'])\n",
    "\n",
    "# Model M3: Reddit Source + User-Generated Features + Feedback Features (Before Logging)\n",
    "X3 = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "        'Authentic', 'WC', 'is_reply', 'reply_avg_incivility', 'num_of_replies', 'votes']]\n",
    "y3 = df['keywords_present_all']\n",
    "model_3 = fit_logistic_regression(X3, y3)\n",
    "print(\"\\nModel 3:\")\n",
    "print_model_summary(model_3)\n",
    "print_model_metrics(model_3)\n",
    "plot_log_odds(X3, model_3.params, ['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes'])\n",
    "\n",
    "# Model M3Log: Reddit Source + User-Generated Features + Feedback Features (Logged)\n",
    "df[['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes']] = df[['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes']].apply(nlog)\n",
    "X3_log = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "             'Authentic', 'WC', 'is_reply', 'reply_avg_incivility', 'num_of_replies', 'votes']]\n",
    "y3_log = df['keywords_present_all']\n",
    "model_3Log = fit_logistic_regression(X3_log, y3_log)\n",
    "print(\"\\nModel 3 Log:\")\n",
    "print_model_summary(model_3Log)\n",
    "print_model_metrics(model_3Log)\n",
    "plot_log_odds(X3_log, model_3Log.params, ['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes'])\n",
    "\n",
    "# Model M4: Reddit Source + User-Generated Features + Feedback Features (Incivility Not Logged)\n",
    "df[['Authentic', 'WC', 'num_of_replies', 'votes']] = df[['Authentic', 'WC', 'num_of_replies', 'votes']].apply(nlog)\n",
    "X4 = df[['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "        'Authentic', 'WC', 'is_reply', 'reply_avg_incivility', 'num_of_replies', 'votes']]\n",
    "y4 = df['keywords_present_all']\n",
    "model_4 = fit_logistic_regression(X4, y4)\n",
    "print(\"\\nModel 4:\")\n",
    "print_model_summary(model_4)\n",
    "print_model_metrics(model_4)\n",
    "plot_log_odds(X4, model_4.params, ['Authentic', 'WC', 'reply_avg_incivility', 'num_of_replies', 'votes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23980f-0e80-4172-8db3-1a339b9ad74b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Descriptives for Log-Transformed Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8272d26-ef1c-472c-9bdf-74766c8efbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def load_and_transform_data(file_path):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Log Transformation\n",
    "    df['Authentic'] = np.log(df['Authentic'])\n",
    "    df['WC'] = np.log(df['WC'])\n",
    "    df['reply_avg_tone'] = np.log(df['reply_avg_tone'])\n",
    "    df['reply_avg_incivility'] = np.log(df['reply_avg_incivility'] + 0.001)\n",
    "    df['num_of_replies'] = np.log(df['num_of_replies'] + 0.001)\n",
    "    df['votes'] = np.log(df['votes'] + 2392.001)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_stats(dataframe, columns):\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        column_data = dataframe[column].dropna()\n",
    "        stats[column] = {\n",
    "            'mean': round(column_data.mean(), 2),\n",
    "            'std_dev': round(column_data.std(), 2),\n",
    "            'min': round(column_data.min(), 2),\n",
    "            'max': round(column_data.max(), 2),\n",
    "            'skewness': round(skew(column_data), 2),\n",
    "            'kurtosis': round(kurtosis(column_data), 2)\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "def analyze_statistics(df, columns):\n",
    "    # Overall statistics\n",
    "    overall_stats = calculate_stats(df, columns)\n",
    "    print(\"Overall Statistics:\")\n",
    "    for column, stats in overall_stats.items():\n",
    "        print(f\"\\n{column}:\")\n",
    "        for stat, value in stats.items():\n",
    "            print(f\"{stat}: {value}\")\n",
    "\n",
    "    # Statistics for keywords_present_all == 1\n",
    "    df_keywords_1 = df[df['keywords_present_all'] == 1]\n",
    "    keywords_1_stats = calculate_stats(df_keywords_1, columns)\n",
    "    print(\"\\nStatistics for keywords_present_all == '1':\")\n",
    "    for column, stats in keywords_1_stats.items():\n",
    "        print(f\"\\n{column}:\")\n",
    "        for stat, value in stats.items():\n",
    "            print(f\"{stat}: {value}\")\n",
    "\n",
    "    # Statistics for keywords_present_all == 0\n",
    "    df_keywords_0 = df[df['keywords_present_all'] == 0]\n",
    "    keywords_0_stats = calculate_stats(df_keywords_0, columns)\n",
    "    print(\"\\nStatistics for keywords_present_all == '0':\")\n",
    "    for column, stats in keywords_0_stats.items():\n",
    "        print(f\"\\n{column}:\")\n",
    "        for stat, value in stats.items():\n",
    "            print(f\"{stat}: {value}\")\n",
    "\n",
    "def main():\n",
    "    file_path = 'final_dataset.csv'\n",
    "    df = load_and_transform_data(file_path)\n",
    "    \n",
    "    # Define columns for which we need statistics\n",
    "    columns = ['Authentic', 'WC', 'reply_avg_tone', 'reply_avg_incivility', 'num_of_replies', 'votes']\n",
    "    \n",
    "    analyze_statistics(df, columns)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd39fa3-a9e6-4ccb-83b6-830a5c29d90e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 3 - Overlap in Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f475d-a7a6-4215-bad5-f673642d2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_rows_across_files(files):\n",
    "    \"\"\"\n",
    "    Counts the total number of rows across multiple CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    files (list of str): List of file paths.\n",
    "\n",
    "    Returns:\n",
    "    int: Total number of rows across all files.\n",
    "    \"\"\"\n",
    "    total_length = sum(pd.read_csv(file).shape[0] for file in files)\n",
    "    return total_length\n",
    "\n",
    "def load_and_concat_data(files, columns):\n",
    "    \"\"\"\n",
    "    Loads CSV files and concatenates them into a single DataFrame, selecting specific columns.\n",
    "\n",
    "    Parameters:\n",
    "    files (list of str): List of file paths.\n",
    "    columns (list of str): Columns to select from each CSV.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Concatenated DataFrame with selected columns.\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(file)[columns] for file in files]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def calculate_overlap_percentages(df):\n",
    "    \"\"\"\n",
    "    Calculates the percentage overlap of authors between subreddits.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing 'subreddit' and 'author' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with overlap percentages between subreddits.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    subreddits = df['subreddit'].unique()\n",
    "    \n",
    "    for sub1 in subreddits:\n",
    "        authors_sub1 = set(df[df['subreddit'] == sub1]['author'])\n",
    "        total_authors_sub1 = len(authors_sub1)\n",
    "        \n",
    "        percentages = {}\n",
    "        for sub2 in subreddits:\n",
    "            if sub1 == sub2:\n",
    "                continue\n",
    "            authors_sub2 = set(df[df['subreddit'] == sub2]['author'])\n",
    "            overlap = authors_sub1 & authors_sub2\n",
    "            overlap_percentage = (len(overlap) / total_authors_sub1) * 100\n",
    "            percentages[sub2] = overlap_percentage\n",
    "        \n",
    "        results[sub1] = percentages\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_unique_authors_count(df):\n",
    "    \"\"\"\n",
    "    Gets the number of unique authors in each subreddit.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing 'subreddit' and 'author' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with the count of unique authors per subreddit.\n",
    "    \"\"\"\n",
    "    unique_counts = {}\n",
    "    subreddits = df['subreddit'].unique()\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        authors = set(df[df['subreddit'] == sub]['author'])\n",
    "        unique_counts[sub] = len(authors)\n",
    "    \n",
    "    return unique_counts\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to save.\n",
    "    filename (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved to {filename}\")\n",
    "\n",
    "# Define file lists\n",
    "raw_files = ['raw_com_proc.csv', 'sg_com_proc.csv', 'tw_com_proc.csv', 'hk_com_proc.csv']\n",
    "sub_files = ['raw_sub_proc.csv', 'sg_sub_proc.csv', 'tw_sub_proc.csv', 'hk_sub_proc.csv']\n",
    "\n",
    "# Get the total number of rows for each set of files\n",
    "total_comments_rows = count_rows_across_files(raw_files)\n",
    "total_authors_rows = count_rows_across_files(sub_files)\n",
    "\n",
    "print(f\"Total number of rows across comment files: {total_comments_rows}\")\n",
    "print(f\"Total number of rows across author files: {total_authors_rows}\")\n",
    "\n",
    "# Load, analyze, and save data for authors in subreddits\n",
    "subreddit_df = load_and_concat_data(sub_files, ['subreddit', 'author'])\n",
    "unique_authors_counts = get_unique_authors_count(subreddit_df)\n",
    "overlap_percentages = calculate_overlap_percentages(subreddit_df)\n",
    "\n",
    "# Create DataFrames for unique author counts and overlap percentages\n",
    "unique_authors_df = pd.DataFrame(list(unique_authors_counts.items()), columns=['Subreddit', 'Unique Authors'])\n",
    "overlap_data = [{'Subreddit 1': sub1, 'Subreddit 2': sub2, 'Overlap Percentage': pct}\n",
    "                for sub1, percentages in overlap_percentages.items()\n",
    "                for sub2, pct in percentages.items()]\n",
    "overlap_df = pd.DataFrame(overlap_data)\n",
    "\n",
    "# Save results to CSV files\n",
    "save_to_csv(unique_authors_df, 'unique_authors_counts_sub.csv')\n",
    "save_to_csv(overlap_df, 'overlap_percentages_sub.csv')\n",
    "\n",
    "# Load, analyze, and save data for authors in comments\n",
    "comment_df = load_and_concat_data(raw_files, ['subreddit', 'author'])\n",
    "unique_authors_counts_comments = get_unique_authors_count(comment_df)\n",
    "overlap_percentages_comments = calculate_overlap_percentages(comment_df)\n",
    "\n",
    "# Create DataFrames for unique author counts and overlap percentages for comments\n",
    "unique_authors_df_comments = pd.DataFrame(list(unique_authors_counts_comments.items()), columns=['Subreddit', 'Unique Authors'])\n",
    "overlap_data_comments = [{'Subreddit 1': sub1, 'Subreddit 2': sub2, 'Overlap Percentage': pct}\n",
    "                         for sub1, percentages in overlap_percentages_comments.items()\n",
    "                         for sub2, pct in percentages.items()]\n",
    "overlap_df_comments = pd.DataFrame(overlap_data_comments)\n",
    "\n",
    "# Save results to CSV files\n",
    "save_to_csv(unique_authors_df_comments, 'unique_authors_counts_comments.csv')\n",
    "save_to_csv(overlap_df_comments, 'overlap_percentages_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d3182-ab2c-461d-805e-c0b5acb7440a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 4 Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2174a57-aff0-4801-93aa-5e14fe54d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_files(file_paths, drop_na=False):\n",
    "    \"\"\"\n",
    "    Processes a list of CSV files to calculate and print statistics.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list of str): List of file paths to process.\n",
    "    drop_na (bool): Whether to drop rows with NaN values in 'Authentic' column.\n",
    "    \"\"\"\n",
    "    total_count = 0\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Drop rows with NaN in 'Authentic' column if specified\n",
    "        if drop_na:\n",
    "            df = df.dropna(subset=['Authentic'])\n",
    "        \n",
    "        # Ensure the column 'keywords_present_all' is binary (0 or 1)\n",
    "        df['keywords_present_all'] = df['keywords_present_all'].astype(int)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        count = (df['keywords_present_all'] == 1).sum()\n",
    "        mean = df['keywords_present_all'].mean()\n",
    "        std_dev = df['keywords_present_all'].std()\n",
    "        num_comments = len(df)\n",
    "\n",
    "        total_count += num_comments\n",
    "        \n",
    "        # Print the results for the current file\n",
    "        print(f\"File: {file_path}\")\n",
    "        print(f\"  Total Number of Comments: {num_comments}\")\n",
    "        print(f\"  Count: {count}\")\n",
    "        print(f\"  Mean: {mean:.3f}\")\n",
    "        print(f\"  Standard Deviation: {std_dev:.3f}\")\n",
    "        print()  # Print a blank line for better readability\n",
    "\n",
    "    print(f\"Total Number of Comments: {total_count}\")\n",
    "\n",
    "# File paths for initial pre-processing\n",
    "initial_file_paths = [\n",
    "    'raw_com_proc.csv',\n",
    "    'sg_com_proc.csv',\n",
    "    'tw_com_proc.csv',\n",
    "    'hk_com_proc.csv'\n",
    "]\n",
    "\n",
    "# File paths for final dataset processing\n",
    "final_file_paths = [\n",
    "    'raw_com_proc_with_replies.csv',\n",
    "    'sg_com_proc_with_replies.csv',\n",
    "    'hk_com_proc_with_replies.csv',\n",
    "    'tw_com_proc_with_replies.csv'\n",
    "]\n",
    "\n",
    "# Process initial files without dropping NaN values\n",
    "print(\"Initial Pre-Processing Results:\")\n",
    "process_files(initial_file_paths)\n",
    "\n",
    "# Process final files with dropping NaN values\n",
    "print(\"Final Dataset Processing Results:\")\n",
    "process_files(final_file_paths, drop_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e333ffa-28c0-4ef6-9e04-59d34e38e1d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 5 Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5131b-70be-4297-bac7-882805219d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_concat(file_paths):\n",
    "    \"\"\"\n",
    "    Reads and concatenates CSV files into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list of str): List of file paths to read and concatenate.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(file) for file in file_paths]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def calculate_grouped_stats(df, columns_of_interest, output_file):\n",
    "    \"\"\"\n",
    "    Groups the DataFrame by 'subreddit', calculates mean and standard deviation,\n",
    "    and exports the results to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to process.\n",
    "    columns_of_interest (list of str): List of columns to calculate statistics for.\n",
    "    output_file (str): Path to save the results.\n",
    "    \"\"\"\n",
    "    grouped = df.groupby('subreddit')[columns_of_interest].agg(['mean', 'std'])\n",
    "    grouped = grouped.round(2).reset_index()\n",
    "    grouped.to_csv(output_file, index=False)\n",
    "    return grouped\n",
    "\n",
    "def print_basic_info(df):\n",
    "    \"\"\"\n",
    "    Prints basic information about the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to get information from.\n",
    "    \"\"\"\n",
    "    print(f'Number of comments: {len(df)}')\n",
    "    print(f'Number of unique subreddits in df: {df[\"subreddit\"].nunique()}')\n",
    "    print(f'Subreddit counts in df:\\n{df[\"subreddit\"].value_counts()}')\n",
    "\n",
    "# File paths for initial processing\n",
    "initial_file_paths = [\n",
    "    'hk_com_proc_with_replies_tb1.csv',\n",
    "    'tw_com_proc_with_replies_tb1.csv',\n",
    "    'sg_com_proc_with_replies_tb1.csv',\n",
    "    'raw_com_proc_with_replies_tb1.csv'\n",
    "]\n",
    "\n",
    "# Load and process the initial data\n",
    "df_before = load_and_concat(initial_file_paths)\n",
    "print(\"Initial Data:\")\n",
    "print_basic_info(df_before)\n",
    "\n",
    "# Define columns of interest\n",
    "columns_of_interest = [\"Authentic\", \"WC\", \"reply_avg_incivility\", \"num_of_replies\", \"votes\"]\n",
    "\n",
    "# Calculate and export statistics before dropping rows\n",
    "grouped_before = calculate_grouped_stats(df_before, columns_of_interest, 'tablex1_beforedrop.csv')\n",
    "\n",
    "# Load the final dataset\n",
    "df_final = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Drop rows with missing values in relevant columns\n",
    "df_final = df_final.dropna(subset=['Authentic', 'WC', 'is_reply', 'keywords_present_all'])\n",
    "\n",
    "print(\"Final Data:\")\n",
    "print_basic_info(df_final)\n",
    "\n",
    "# Calculate and export statistics after dropping rows\n",
    "grouped_after = calculate_grouped_stats(df_final, columns_of_interest, 'tablex1_afterdrop.csv')\n",
    "\n",
    "print(\"Exporting done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d59196-5198-4413-8b95-638764257576",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 6 Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28be96-729f-476c-8b3c-f990b5186e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Initial Pre-processing\n",
    "import pandas as pd\n",
    "\n",
    "#Obtain descriptives for Table 5\n",
    "df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Drop rows with missing values in the relevant columns\n",
    "df = df.dropna(subset=['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "                                'Authentic', 'WC', 'is_reply', 'keywords_present_all'])\n",
    "\n",
    "print(f\"Number of Comments: {len(df)}\")\n",
    "\n",
    "#Note: 65872 of the comments do not have authenticity score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_statistics(df, columns):\n",
    "    # Initialize dictionary to hold the results\n",
    "    stats = {}\n",
    "\n",
    "    # Count the number of observations\n",
    "    stats['count'] = df.shape[0]\n",
    "\n",
    "    # Calculate statistics for each column\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            stats[column] = {\n",
    "                'mean': round(df[column].mean(), 2),\n",
    "                'std_dev': round(df[column].std(), 2),\n",
    "                'min': round(df[column].min(), 2),\n",
    "                'max': round(df[column].max(), 2),\n",
    "                'skewness': round(skew(df[column].dropna()), 2),\n",
    "                'kurtosis': round(kurtosis(df[column].dropna()), 2)\n",
    "            }\n",
    "        else:\n",
    "            stats[column] = 'Column not found'\n",
    "\n",
    "    return stats\n",
    "\n",
    "def create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent):\n",
    "    # Initialize an empty DataFrame\n",
    "    stats_df = pd.DataFrame()\n",
    "\n",
    "    # Flatten the dictionary and convert it into a DataFrame\n",
    "    for group_name, stats_dict in {\n",
    "        'All Data': all_stats,\n",
    "        'Keywords Present (1)': stats_keywords_present,\n",
    "        'Keywords Absent (0)': stats_keywords_absent\n",
    "    }.items():\n",
    "        # Convert each group's statistics into a DataFrame\n",
    "        stats_data = {k: v for k, v in stats_dict.items() if isinstance(v, dict)}\n",
    "        stats_df_group = pd.DataFrame(stats_data).T\n",
    "        stats_df_group['Group'] = group_name\n",
    "        stats_df = pd.concat([stats_df, stats_df_group])\n",
    "\n",
    "    # Reset the index for better readability\n",
    "    stats_df.reset_index(inplace=True)\n",
    "    stats_df.rename(columns={'index': 'Statistic'}, inplace=True)\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "# Define the columns of interest\n",
    "columns_of_interest = [\"Authentic\", \"WC\", \"reply_avg_incivility\", \"num_of_replies\", \"votes\"]\n",
    "\n",
    "# Calculate statistics for the entire dataframe\n",
    "all_stats = calculate_statistics(df, columns_of_interest)\n",
    "\n",
    "# Calculate statistics for when df['keywords_present_all'] == 1\n",
    "stats_keywords_present = calculate_statistics(df[df['keywords_present_all'] == 1], columns_of_interest)\n",
    "\n",
    "# Calculate statistics for when df['keywords_present_all'] == 0\n",
    "stats_keywords_absent = calculate_statistics(df[df['keywords_present_all'] == 0], columns_of_interest)\n",
    "\n",
    "# Create DataFrame from the statistics\n",
    "stats_df = create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "stats_df.to_csv('Table5_summary.csv', index=False)\n",
    "\n",
    "print(\"Statistics have been exported to 'Table6_summary.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45c3ba-db5e-47d7-95e1-0285853b376b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table 7 Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df8adc-efc1-4743-8509-17d12bb75e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def nlog(score, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Apply the logarithmic transformation to the given score.\n",
    "\n",
    "    Parameters:\n",
    "    score (float or array-like): The value or array of values to transform.\n",
    "    epsilon (float): Small value to prevent log of zero.\n",
    "\n",
    "    Returns:\n",
    "    float or array-like: Transformed value or array of values.\n",
    "    \"\"\"\n",
    "    return np.sign(score) * np.log(np.abs(score) + epsilon)\n",
    "\n",
    "def calculate_statistics(df, columns):\n",
    "    \"\"\"\n",
    "    Calculate various statistics for specified columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to calculate statistics on.\n",
    "    columns (list of str): List of column names to calculate statistics for.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing statistics for each column.\n",
    "    \"\"\"\n",
    "    stats = {'count': df.shape[0]}\n",
    "\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            stats[column] = {\n",
    "                'mean': round(df[column].mean(), 2),\n",
    "                'std_dev': round(df[column].std(), 2),\n",
    "                'min': round(df[column].min(), 2),\n",
    "                'max': round(df[column].max(), 2),\n",
    "                'skewness': round(skew(df[column].dropna()), 2),\n",
    "                'kurtosis': round(kurtosis(df[column].dropna()), 2)\n",
    "            }\n",
    "        else:\n",
    "            stats[column] = 'Column not found'\n",
    "\n",
    "    return stats\n",
    "\n",
    "def create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from the calculated statistics.\n",
    "\n",
    "    Parameters:\n",
    "    all_stats (dict): Statistics for all data.\n",
    "    stats_keywords_present (dict): Statistics where 'keywords_present_all' is 1.\n",
    "    stats_keywords_absent (dict): Statistics where 'keywords_present_all' is 0.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing all statistics.\n",
    "    \"\"\"\n",
    "    stats_df = pd.DataFrame()\n",
    "\n",
    "    stats_dict = {\n",
    "        'All Data': all_stats,\n",
    "        'Keywords Present (1)': stats_keywords_present,\n",
    "        'Keywords Absent (0)': stats_keywords_absent\n",
    "    }\n",
    "\n",
    "    for group_name, stats_data in stats_dict.items():\n",
    "        stats_df_group = pd.DataFrame(stats_data).T\n",
    "        stats_df_group['Group'] = group_name\n",
    "        stats_df = pd.concat([stats_df, stats_df_group])\n",
    "\n",
    "    stats_df.reset_index(inplace=True)\n",
    "    stats_df.rename(columns={'index': 'Statistic'}, inplace=True)\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def print_counts(df):\n",
    "    \"\"\"\n",
    "    Print counts of comments based on different criteria.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to get counts from.\n",
    "    \"\"\"\n",
    "    print(\"Number of total comments:\", len(df))\n",
    "    print(\"Number of queer comments:\", len(df[df['keywords_present_all'] == 1]))\n",
    "    print(\"Number of non-queer comments:\", len(df[df['keywords_present_all'] == 0]))\n",
    "    print(\"Number of SGRaw comments:\", len(df[df['subreddit'] == 'SingaporeRaw']))\n",
    "    print(\"Number of SG comments:\", len(df[df['subreddit'] == 'singapore']))\n",
    "    print(\"Number of HK comments:\", len(df[df['subreddit'] == 'HongKong']))\n",
    "    print(\"Number of TW comments:\", len(df[df['subreddit'] == 'taiwan']))\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Load dataset\n",
    "    df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "    # Drop rows with missing values in the relevant columns\n",
    "    df = df.dropna(subset=['subreddit_HongKong', 'subreddit_singapore', 'subreddit_taiwan',\n",
    "                            'Authentic', 'WC', 'is_reply', 'keywords_present_all'])\n",
    "\n",
    "    # Apply the transformation function\n",
    "    columns_to_transform = [\"Authentic\", \"WC\", \"reply_avg_incivility\", \"num_of_replies\", \"votes\"]\n",
    "    for column in columns_to_transform:\n",
    "        df[column] = nlog(df[column])\n",
    "\n",
    "    # Calculate statistics\n",
    "    all_stats = calculate_statistics(df, columns_to_transform)\n",
    "    stats_keywords_present = calculate_statistics(df[df['keywords_present_all'] == 1], columns_to_transform)\n",
    "    stats_keywords_absent = calculate_statistics(df[df['keywords_present_all'] == 0], columns_to_transform)\n",
    "\n",
    "    # Create and export the DataFrame with statistics\n",
    "    stats_df = create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent)\n",
    "    stats_df.to_csv('Table6_summary.csv', index=False)\n",
    "    print(\"Statistics have been exported to 'Table6_summary.csv'.\")\n",
    "\n",
    "    # Print counts\n",
    "    print_counts(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78db07e-f0de-4455-9385-7b4afd3e9fa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table B1 Descriptives / Appendix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dac3fa-1606-4a7e-88a1-89c5d79c4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def merge_incivility(df):\n",
    "    \"\"\"\n",
    "    Calculates the average incivility for each 'parent_id', merges this information\n",
    "    back into the original dataframe, and fills missing values.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy(deep=True)\n",
    "    result = df_copy.groupby('parent_id').agg({\n",
    "        'incivility_prop': 'mean'\n",
    "    }).reset_index()\n",
    "    result['parent_id'] = result['parent_id'].str.replace(r'^t[13]_', '', regex=True)\n",
    "    result = result.rename(columns={\n",
    "        'parent_id': 'id', \n",
    "        'incivility_prop': 'reply_avg_incivility'\n",
    "    })\n",
    "    df_merged = pd.merge(df, result, on='id', how='left')\n",
    "    df_merged['reply_avg_incivility'] = df_merged['reply_avg_incivility'].fillna(0)\n",
    "    return df_merged\n",
    "\n",
    "def process_files(input_files, output_files):\n",
    "    \"\"\"\n",
    "    Process a list of input CSV files to calculate average incivility and save results to output CSV files.\n",
    "    \"\"\"\n",
    "    for input_file, output_file in zip(input_files, output_files):\n",
    "        df = pd.read_csv(input_file)\n",
    "        df = merge_incivility(df)\n",
    "        df.to_csv(output_file, index=False)\n",
    "    print(\"Processing complete. Modified files saved.\")\n",
    "\n",
    "def read_and_concatenate_files(file_paths):\n",
    "    \"\"\"\n",
    "    Read and concatenate a list of CSV files into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths to read.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(file) for file in file_paths]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def calculate_statistics(df, columns):\n",
    "    \"\"\"\n",
    "    Calculate various statistics for specified columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to calculate statistics on.\n",
    "    columns (list of str): List of column names to calculate statistics for.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing statistics for each column.\n",
    "    \"\"\"\n",
    "    stats = {'count': df.shape[0]}\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            stats[column] = {\n",
    "                'mean': round(df[column].mean(), 2),\n",
    "                'std_dev': round(df[column].std(), 2),\n",
    "                'min': round(df[column].min(), 2),\n",
    "                'max': round(df[column].max(), 2),\n",
    "                'skewness': round(skew(df[column].dropna()), 2),\n",
    "                'kurtosis': round(kurtosis(df[column].dropna()), 2)\n",
    "            }\n",
    "        else:\n",
    "            stats[column] = 'Column not found'\n",
    "    return stats\n",
    "\n",
    "def create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from the calculated statistics.\n",
    "\n",
    "    Parameters:\n",
    "    all_stats (dict): Statistics for all data.\n",
    "    stats_keywords_present (dict): Statistics where 'keywords_present_all' is 1.\n",
    "    stats_keywords_absent (dict): Statistics where 'keywords_present_all' is 0.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing all statistics.\n",
    "    \"\"\"\n",
    "    stats_df = pd.DataFrame()\n",
    "    stats_dict = {\n",
    "        'All Data': all_stats,\n",
    "        'Keywords Present (1)': stats_keywords_present,\n",
    "        'Keywords Absent (0)': stats_keywords_absent\n",
    "    }\n",
    "\n",
    "    for group_name, stats_data in stats_dict.items():\n",
    "        stats_data = {k: v for k, v in stats_data.items() if isinstance(v, dict)}\n",
    "        stats_df_group = pd.DataFrame(stats_data).T\n",
    "        stats_df_group['Group'] = group_name\n",
    "        stats_df = pd.concat([stats_df, stats_df_group])\n",
    "\n",
    "    stats_df.reset_index(inplace=True)\n",
    "    stats_df.rename(columns={'index': 'Statistic'}, inplace=True)\n",
    "    return stats_df\n",
    "\n",
    "def print_missing_values_summary(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    Print the number of missing values for specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to check.\n",
    "    columns_to_check (list of str): Columns to check for missing values.\n",
    "    \"\"\"\n",
    "    missing_values_count = df[columns_to_check].isna().sum()\n",
    "    print(\"Number of missing values for each variable:\")\n",
    "    print(missing_values_count)\n",
    "\n",
    "def print_comments_summary(df):\n",
    "    \"\"\"\n",
    "    Print summary statistics for comments based on different criteria.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame to summarize.\n",
    "    \"\"\"\n",
    "    print(f\"Number of total comments: {len(df)}\")\n",
    "    print(f\"Number of queer comments: {len(df[df['keywords_present_all'] == 1])}\")\n",
    "    print(f\"Number of non-queer comments: {len(df[df['keywords_present_all'] == 0])}\")\n",
    "    print(f\"Number of SGRaw comments: {len(df[df['subreddit'] == 'SingaporeRaw'])}\")\n",
    "    print(f\"Number of SG comments: {len(df[df['subreddit'] == 'singapore'])}\")\n",
    "    print(f\"Number of HK comments: {len(df[df['subreddit'] == 'HongKong'])}\")\n",
    "    print(f\"Number of TW comments: {len(df[df['subreddit'] == 'taiwan'])}\")\n",
    "\n",
    "def main():\n",
    "    # Step 2: Average the replies of incivility, regardless of word count\n",
    "    input_files = [\n",
    "        'merged_hk_com_proc_with_replies.csv',\n",
    "        'merged_tw_com_proc_with_replies.csv',\n",
    "        'merged_sg_com_proc_with_replies.csv',\n",
    "        'merged_raw_com_proc_with_replies.csv'\n",
    "    ]\n",
    "    output_files = [\n",
    "        'hk_com_proc_with_replies_tb1.csv',\n",
    "        'tw_com_proc_with_replies_tb1.csv',\n",
    "        'sg_com_proc_with_replies_tb1.csv',\n",
    "        'raw_com_proc_with_replies_tb1.csv'\n",
    "    ]\n",
    "\n",
    "    process_files(input_files, output_files)\n",
    "\n",
    "    # Read and concatenate all processed files into a single DataFrame\n",
    "    file_paths = output_files\n",
    "    df = read_and_concatenate_files(file_paths)\n",
    "    \n",
    "    print(df.head())\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "    # Define columns of interest\n",
    "    columns_of_interest = [\"Authentic\", \"WC\", \"reply_avg_incivility\", \"num_of_replies\", \"votes\"]\n",
    "\n",
    "    # Calculate statistics\n",
    "    all_stats = calculate_statistics(df, columns_of_interest)\n",
    "    stats_keywords_present = calculate_statistics(df[df['keywords_present_all'] == 1], columns_of_interest)\n",
    "    stats_keywords_absent = calculate_statistics(df[df['keywords_present_all'] == 0], columns_of_interest)\n",
    "\n",
    "    # Create and export the DataFrame with statistics\n",
    "    stats_df = create_statistics_df(all_stats, stats_keywords_present, stats_keywords_absent)\n",
    "    stats_df.to_csv('TableB1_summary.csv', index=False)\n",
    "    print(\"Statistics have been exported to 'TableB1_summary.csv'.\")\n",
    "\n",
    "    # Print missing values summary\n",
    "    print_missing_values_summary(df, columns_of_interest)\n",
    "\n",
    "    # Print comments summary\n",
    "    print_comments_summary(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
